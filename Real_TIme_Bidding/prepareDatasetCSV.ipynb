{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prepareDatasetCSV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzTHXSZkTajM",
        "outputId": "4dc80894-1c5a-41c4-90b3-3e713e2386d0"
      },
      "source": [
        "#Mounting the drive to the colab workspace.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH2YMU1EAmnJ"
      },
      "source": [
        "#Notebook 1: Dataset Prepartion\n",
        "****\n",
        "**Overview of the notebook**\n",
        "* The bz2 file of the iPinYou dataset is downloaded from [here](https://figshare.com/articles/dataset/ipinyou_contest_dataset_season2/5732328/1).\n",
        "* The file is unzipped in to '*Datasets/ipinyou*'.\n",
        "* Following which the data for different days were composed to form a single log file using the shell script ''.\n",
        "* Then suitable python scripts are written to convert the log.txt files in to csv files which are stored in TRAIN and TEST respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrB3kDkPUZlm"
      },
      "source": [
        "#Importing the required libraries.\n",
        "import os\n",
        "import pandas as pd\n",
        "import bz2\n",
        "import csv\n",
        "import codecs\n",
        "import itertools\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQWr4TVwR2f9",
        "outputId": "e2f62a1d-8b29-4241-8171-d6fba21b46d0"
      },
      "source": [
        "#Navigating to main directory.\n",
        "root_dir = r'/content/drive/My Drive/HS4007/Real_Time_Bidding'\n",
        "os.chdir(root_dir)\n",
        "#Sanity Check.\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/HS4007/Real_Time_Bidding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73wFXdVQDbQA"
      },
      "source": [
        "## Running the shell script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwDBRdYUwY2I",
        "outputId": "1374f4d1-cad4-4351-b92a-52ed315889aa"
      },
      "source": [
        "%%shell\n",
        "\n",
        "echo \"Hi,I am bash and I'm here to make your life easier!\"\n",
        "\n",
        "echo \"Current Working Directory: $PWD\"\n",
        "\n",
        "ipin=./Datasets/ipinyou\n",
        "#Path for training and test datasets.\n",
        "train=./Datasets/ipinyou/train\n",
        "test=./Datasets/ipinyou/test\n",
        "\n",
        "#Creating the directories for train and test if they do not exist.\n",
        "if [ ! -d \"$train\" ]\n",
        "then\n",
        "   mkdir -p $train \n",
        "fi\n",
        "\n",
        "if [ ! -d \"$test\" ]\n",
        "then\n",
        "   mkdir -p $test \n",
        "fi\n",
        " \n",
        "echo \"I just  made the train and test folders at the path you mentioned!\"\n",
        "\n",
        "__unzip__ (){\n",
        "    echo \"I am going to unzip bz2 files.\" \n",
        "    cp $ipin/training2nd/imp.*.bz2 $train\n",
        "    cp $ipin/training2nd/clk.*.bz2 $train\n",
        "    bzip2 -d $train/* \n",
        "    cp $ipin/testing2nd/* $test\n",
        "    bzip2 -d $test/*\n",
        "    echo \"Done done done!!!\"\n",
        "}\n",
        "\n",
        "#Run this only if the 'Datasets/ipinyou/train' folder is empty.\n",
        "train_files=(${train}/*.txt)\n",
        "test_files=(${test}/*.txt)\n",
        "\n",
        "if ((${#train_files[@]} && ${#test_files[@]}))\n",
        "then\n",
        "    echo \"Already unzipped.\"\n",
        "else\n",
        "    echo \"Unzipping...\"\n",
        "    __unzip__\n",
        "    echo \"Done unzipping.\" \n",
        "fi\n",
        "\n",
        "\n",
        "if [ ! -f \"$train/clk_logs.txt\" ]\n",
        "then \n",
        "    echo \"I am combining all the logs of click in to single file.\"\n",
        "    cat $train/clk*.txt > $train/clk_logs.txt\n",
        "else\n",
        "    echo \"Already prepared a single clicks logs file.\"\n",
        "fi\n",
        "\n",
        "if [ ! -f \"$train/imp_logs.txt\" ]\n",
        "then \n",
        "    echo \"I am combining all the logs of impressions in to a single file.\"\n",
        "    cat $train/imp*.txt > $train/imp_logs.txt\n",
        "else\n",
        "    echo \"Already prepared a single impressions logs file.\"\n",
        "fi\n",
        "\n",
        "if [ ! -f \"$test/raw_test.txt\" ]\n",
        "then\n",
        "    cat $test/*.txt > $test/raw_test.txt\n",
        "else\n",
        "    echo \"Test file is also prepared.\"\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi,I am bash and I'm here to make your life easier!\n",
            "Current Working Directory: /content/drive/My Drive/HS4007/Real_Time_Bidding\n",
            "I just  made the train and test folders at the path you mentioned!\n",
            "Already unzipped.\n",
            "Already prepared a single clicks logs file.\n",
            "Already prepared a single impressions logs file.\n",
            "Test file is also prepared.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbDIK0DkDgev"
      },
      "source": [
        "## Creation of csv files and dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOjYEa6PSYCH"
      },
      "source": [
        "class read_dataset(object):\n",
        "    '''\n",
        "    A base class for reading the log data files that can be used\n",
        "    for getting files of all advertisers.\n",
        "    '''\n",
        "    def __init__(self,dataset_path,target_file_path):\n",
        "        '''\n",
        "        Initializing the instace of the base class.\n",
        "        \n",
        "        Args:\n",
        "             dataset_path (str)-> The path in which training or\n",
        "                                  testing datset is located.\n",
        "             target_file (str) -> Path to which the created csv file \n",
        "                                  should be stored.\n",
        "        '''\n",
        "        self.path = dataset_path\n",
        "        self.tf = target_file_path\n",
        "        self.columns = ['bid_id','timestamp','log_type','ipinyou_id','user_agent','ip_address',\n",
        "        'region_id','city_id','ad_exchange','domain','url','anonymous_url_id',\n",
        "        'ad_slot_id','ad_slot_width','ad_slot_height','ad_slot_visibility',\n",
        "        'ad_slot','ad_slot_floor_price','creative_id','bidding_price',\n",
        "        'paying_price','key_page_url','advertiser_id','user_tags']\n",
        "\n",
        "    def print_progress(self,line):\n",
        "        '''\n",
        "        A method that prints the progress of write/read.\n",
        "\n",
        "        Args:\n",
        "\n",
        "             line (list) -> The current line being processed.\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def reject_row(self,row):\n",
        "        '''\n",
        "        A method for filtering the rows.\n",
        "\n",
        "        Args:\n",
        "             \n",
        "             row (list) -> The row to be verified.\n",
        "        \n",
        "        Returns: (bool) -> If True, reject the row.\n",
        "        '''\n",
        "        if len(row)<24:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def get_csv(self):\n",
        "        '''\n",
        "        A method which converts the txt file into a csv file \n",
        "        that is readymade for pandas.\n",
        "        '''\n",
        "        #Checking the existence of a file.\n",
        "        if os.path.isfile(self.tf):\n",
        "            print(f'Would you look at that, the csv file has already been created.')\n",
        "            return\n",
        "        #Opeing the files.\n",
        "        with codecs.open(self.path,'r',encoding='utf-8',errors='ignore') as csv_file:\n",
        "            logs_reader = csv.reader(csv_file, delimiter='\\t')\n",
        "            print(f'Let me begin the writing of the csv file...')\n",
        "            \n",
        "            w_progress = 0\n",
        "            with open(self.tf, 'w') as new_csv_file:\n",
        "                #The column names.\n",
        "                fieldnames = self.columns\n",
        "\n",
        "                csv_writer = csv.DictWriter(new_csv_file,fieldnames=fieldnames)\n",
        "                csv_writer.writeheader()\n",
        "\n",
        "                for row in logs_reader:\n",
        "                    # A filter for rows.\n",
        "                    if self.reject_row(row):\n",
        "                        continue\n",
        "                    csv_writer.writerow(self.apply_schema(row))\n",
        "        print(f'Written Sucesfully')\n",
        "\n",
        "\n",
        "    def apply_schema(self,row):\n",
        "        '''\n",
        "        A method that converts a row read from the text file in to \n",
        "        a meaningful log.\n",
        "\n",
        "        Args:\n",
        "             row (list) -> corresponds to elements from a line \n",
        "                           of the text file.\n",
        "        Returns: (dict)\n",
        "        '''\n",
        "        log = {}\n",
        "        index = list(range(len(row)))\n",
        "\n",
        "        for key,value in zip(self.columns,index):\n",
        "            log[key] = row[value]\n",
        "            \n",
        "        return log\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUUISSl-8MQS"
      },
      "source": [
        "## Training Datasets Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awB0EqjuSYOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127b0c88-cbc5-4da9-e9c6-751df0a7de83"
      },
      "source": [
        "#Paths to impressions and clicks datafile for training.\n",
        "imp_log_path = root_dir + \"/Datasets/ipinyou/train/imp_logs.txt\"\n",
        "clk_log_path = root_dir + \"/Datasets/ipinyou/train/clk_logs.txt\"\n",
        "tst_log_path = root_dir + \"//Datasets/ipinyou/test/raw_test.txt\"\n",
        "\n",
        "#Arguments for the class instances.\n",
        "imp_kargs=  {'dataset_path': imp_log_path,'target_file_path':'TRAIN/imp_logs.csv'}\n",
        "clk_kargs = {'dataset_path': clk_log_path, 'target_file_path':'TRAIN/clk_logs.csv'}\n",
        "tst_kargs = {'dataset_path': tst_log_path, 'target_file_path':'TEST/tst_logs.csv'}\n",
        "\n",
        "logs = ['imp','clk']\n",
        "#An instace of classes.\n",
        "imp_reader = read_dataset(**imp_kargs)\n",
        "clk_reader = read_dataset(**clk_kargs)\n",
        "tst_reader=read_dataset(**tst_kargs)\n",
        "readers=[imp_reader,clk_reader,tst_reader]\n",
        "\n",
        "#Creating the csv files.\n",
        "for reader in readers:\n",
        "    reader.get_csv()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Would you look at that, the csv file has already been created.\n",
            "Would you look at that, the csv file has already been created.\n",
            "Would you look at that, the csv file has already been created.\n"
          ]
        }
      ]
    }
  ]
}